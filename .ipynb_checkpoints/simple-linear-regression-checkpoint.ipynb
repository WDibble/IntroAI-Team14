{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02f1ef-0790-4adb-9073-90408c4a56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import calendar\n",
    "import datetime\n",
    "import pytz\n",
    "import scipy.stats\n",
    "import dateutil.parser\n",
    "import time\n",
    "#import requests\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from math import sqrt\n",
    "from alive_progress import alive_bar\n",
    "#from json.decoder import JSONDecodeError\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Dataset/1900_2021_DISASTERS.csv')\n",
    "\n",
    "# View the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509065d-9ac1-4bdf-b775-1ceb708d0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df = df.drop(['Adm Level', 'Admin1 Code', 'Admin2 Code', 'Geo Locations', 'Disaster Group', 'Year', 'Glide', 'Seq', 'Local Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594be6a-6352-482f-8866-ca1ea3c6119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all cathegorical features homogenous, useful for sentimental analysis\n",
    "cols = ['Disaster Subgroup', 'Disaster Type', 'Disaster Subtype', 'Disaster Subsubtype', 'Event Name', 'Country', 'ISO', 'Region', 'Continent', 'Location', 'Origin', 'Associated Dis', 'Associated Dis2', 'OFDA Response', 'Appeal', 'Declaration', 'Dis Mag Scale', 'River Basin']\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].str.lower()\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f8445-b6e8-4d5e-ac56-ca156a74bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly interpolate numeric columns\n",
    "numeric = df[['Start Day', 'Start Month', 'End Day', 'End Month']]\n",
    "              #, 'CPI','Total Affected', 'No Homeless', 'No Affected', 'No Injured', 'Total Deaths']]\n",
    "numeric_columns = numeric.columns\n",
    "\n",
    "df[numeric_columns] = df[numeric_columns].interpolate(method='linear',limit_direction='forward')\n",
    "\n",
    "# Calculate the median and interquartile range of the date columns\n",
    "start_month_median = df['Start Month'].median()\n",
    "start_month_iqr = df['Start Month'].quantile(0.75) - df['Start Month'].quantile(0.25)\n",
    "\n",
    "start_day_median = df['Start Day'].median()\n",
    "start_day_iqr = df['Start Day'].quantile(0.75) - df['Start Day'].quantile(0.25)\n",
    "\n",
    "end_month_median = df['End Month'].median()\n",
    "end_month_iqr = df['End Month'].quantile(0.75) - df['End Month'].quantile(0.25)\n",
    "\n",
    "end_day_median = df['End Day'].median()\n",
    "end_day_iqr = df['End Day'].quantile(0.75) - df['End Day'].quantile(0.25)\n",
    "\n",
    "# Replace any outliers with the median and interquartile range\n",
    "df['Start Month'] = df['Start Month'].apply(lambda x: start_month_median if x > start_month_median + start_month_iqr * 1.5 or x < start_month_median - start_month_iqr * 1.5 else x)\n",
    "df['Start Day'] = df['Start Day'].apply(lambda x: start_day_median if x > start_day_median + start_day_iqr * 1.5 or x < start_day_median - start_day_iqr * 1.5 else x)\n",
    "df['End Month'] = df['End Month'].apply(lambda x: end_month_median if x > end_month_median + end_month_iqr * 1.5 or x < end_month_median - end_month_iqr * 1.5 else x)\n",
    "df['End Day'] = df['End Day'].apply(lambda x: end_day_median if x > end_day_median + end_day_iqr * 1.5 or x < end_day_median - end_day_iqr * 1.5 else x)\n",
    "\n",
    "# Replace infinite values with the median and interquartile range\n",
    "df['Start Month'] = df['Start Month'].apply(lambda x: start_month_median if np.isinf(x) else x)\n",
    "df['Start Day'] = df['Start Day'].apply(lambda x: start_day_median if np.isinf(x) else x)\n",
    "df['End Month'] = df['End Month'].apply(lambda x: end_month_median if np.isinf(x) else x)\n",
    "df['End Day'] = df['End Day'].apply(lambda x: end_day_median if np.isinf(x) else x)\n",
    "\n",
    "# Replace non-finite values with the median and interquartile range\n",
    "df['Start Month'] = df['Start Month'].apply(lambda x: start_month_median if not np.isfinite(x) else x)\n",
    "df['Start Day'] = df['Start Day'].apply(lambda x: start_day_median if not np.isfinite(x) else x)\n",
    "df['End Month'] = df['End Month'].apply(lambda x: end_month_median if not np.isfinite(x) else x)\n",
    "df['End Day'] = df['End Day'].apply(lambda x: end_day_median if not np.isfinite(x) else x)\n",
    "\n",
    "# Throw away fractorial parts with a cast to int\n",
    "df[\n",
    "    ['Start Year','Start Month','Start Day',\n",
    "     'End Year','End Month','End Day'\n",
    "    ]\n",
    "] = df[\n",
    "    ['Start Year','Start Month','Start Day',\n",
    "     'End Year','End Month','End Day'\n",
    "    ]\n",
    "].astype(np.int64)\n",
    "\n",
    "# Check if the day is out of range for the given month, and if it is, increment the month by 1 and set the day to 1\n",
    "def check_start_date_validity(row):\n",
    "    # Get the year, month, and day\n",
    "    year = row['Start Year']\n",
    "    month = row['Start Month']\n",
    "    day = row['Start Day']\n",
    "    # Check if the month is February\n",
    "    if month == 2:\n",
    "        # Check if the day is greater than 28\n",
    "        if day > 28:\n",
    "            # Set the day to 1\n",
    "            row['Start Day'] = 1\n",
    "            # Increment the month by 1\n",
    "            row['Start Month'] += 1\n",
    "    else:\n",
    "        # Get the days in the month\n",
    "        days_in_month = calendar.monthrange(year, month)[1]\n",
    "        # Check if the day is greater than the days in the month\n",
    "        if day > days_in_month:\n",
    "            # Set the day to 1\n",
    "            row['Start Day'] = 1\n",
    "            # Increment the month by 1\n",
    "            row['Start Month'] += 1\n",
    "            # Check if the month is greater than 12\n",
    "            if row['Start Month'] > 12:\n",
    "                # Set the month to 1\n",
    "                row['Start Month'] = 1\n",
    "                # Increment the year by 1\n",
    "                row['Start Year'] += 1\n",
    "    # Return the row\n",
    "    return row\n",
    "\n",
    "def check_end_date_validity(row):\n",
    "    # Get the year, month, and day\n",
    "    year = row['End Year']\n",
    "    month = row['End Month']\n",
    "    day = row['End Day']\n",
    "    # Check if the month is February\n",
    "    if month == 2:\n",
    "        # Check if the day is greater than 28\n",
    "        if day > 28:\n",
    "            # Set the day to 1\n",
    "            row['End Day'] = 1\n",
    "            # Increment the month by 1\n",
    "            row['End Month'] += 1\n",
    "    else:\n",
    "        # Get the days in the month\n",
    "        days_in_month = calendar.monthrange(year, month)[1]\n",
    "        # Check if the day is greater than the days in the month\n",
    "        if day > days_in_month:\n",
    "            # Set the day to 1\n",
    "            row['End Day'] = 1\n",
    "            # Increment the month by 1\n",
    "            row['End Month'] += 1\n",
    "            # Check if the month is greater than 12\n",
    "            if row['End Month'] > 12:\n",
    "                # Set the month to 1\n",
    "                row['End Month'] = 1\n",
    "                # Increment the year by 1\n",
    "                row['End Year'] += 1\n",
    "    # Return the row\n",
    "    return row\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df[['Start Year','Start Month','Start Day']] = df[['Start Year','Start Month','Start Day']].apply(check_start_date_validity, axis=1)\n",
    "df[['End Year','End Month','End Day']] = df[['End Year','End Month','End Day']].apply(check_end_date_validity, axis=1)\n",
    "\n",
    "# Create a new columns to store the start & end dates\n",
    "df['Start Date'] = np.nan\n",
    "df['End Date'] = np.nan\n",
    "\n",
    "# Iterate through the rows in the dataframe to create start and end dates, make them time zone aware if wanted\n",
    "for index, row in df.iterrows():\n",
    "    # Get the timezone if needed\n",
    "    #tz = row['Timezone']\n",
    "    \n",
    "    # Create a start datetime object from the values in the row\n",
    "    dt_start = datetime.datetime(row['Start Year'], row['Start Month'], row['Start Day'])\n",
    "    # Make the start date timezone-aware if needed\n",
    "    #dt_start = pytz.timezone(tz).localize(dt_start)\n",
    "    # Store the start datetime in the new column\n",
    "    df.loc[index, 'Start Date'] = dt_start\n",
    "    \n",
    "    # Similary for the end date\n",
    "    dt_end = datetime.datetime(row['End Year'], row['End Month'], row['End Day'])\n",
    "    # Make the end date timezone-aware if needed\n",
    "    #dt_end = pytz.timezone(tz).localize(dt_end)\n",
    "    # Store the end date in the new column\n",
    "    df.loc[index, 'End Date'] = dt_end\n",
    "    \n",
    "# Format the new dates columns\n",
    "df['Start Date'] = pd.to_datetime(df['Start Date'], format=\"%Y-%m-%d\")\n",
    "df['End Date'] = pd.to_datetime(df['End Date'], format=\"%Y-%m-%d\")\n",
    "# Format the new dates if time zone aware\n",
    "# df['Start Date'] = pd.to_datetime(df['Start Date'], format=\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "# df['End Date'] = pd.to_datetime(df['End Date'], format=\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "# Drop the Start Year, Start Month, Start Day, End Year, End Month, End Day clumns, keep them if wanted\n",
    "df = df.drop(columns=['Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day'])\n",
    "\n",
    "# Export as csv if dates are time zone aware\n",
    "#df.to_csv(\"Analysis/Result/dst-test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ce03e-73ce-41f2-9eec-1abb0dea163a",
   "metadata": {},
   "source": [
    "### TO NOTE: Monetary values are not interpolated so NaN's must be handled first before using the below regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1119c4-cf94-4be9-b95e-d66abb7c315c",
   "metadata": {},
   "source": [
    "### Develop a regression model to backcast the adjusted historical monetary values over a timeseries by picking the best prediction out of 20 and assigning it the respective monetary columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7495ebd-0ae5-4deb-9274-14c808015951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns and initialize them to null\n",
    "df['Start Date TS'] = None\n",
    "df['End Date TS'] = None\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the start and end dates\n",
    "    start_date = row['Start Date']\n",
    "    end_date = row['End Date']\n",
    "    \n",
    "    # Convert the start and end dates to timestamps\n",
    "    start_timestamp = start_date.timestamp()\n",
    "    end_timestamp = end_date.timestamp()\n",
    "    \n",
    "    # Assign the timestamps to the new columns\n",
    "    df.at[index, 'Start Date TS'] = start_timestamp\n",
    "    df.at[index, 'End Date TS'] = end_timestamp\n",
    "\n",
    "df[['Start Date TS', 'End Date TS']] = float(int(df[['Start Date TS', 'End Date TS']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106809f-1bef-4d0d-9e23-bcd08ed9559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare the data\n",
    "X =  df[['Start Date TS', 'End Date TS']]\n",
    "y1 = df[\"Insured Damages ('000 US$)\"]\n",
    "y2 = df[\"Total Damages ('000 US$)\"]\n",
    "y3 = df['Aid Contribution']\n",
    "\n",
    "# Impute missing values with the mean, median, or mode of the column\n",
    "X = X.fillna(X.mean())\n",
    "y1 = y1.fillna(y1.mean())\n",
    "y2 = y2.fillna(y2.mean())\n",
    "y3 = y3.fillna(y3.mean())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test, y3_train, y3_test = train_test_split(X, y1, y2, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y1_train)\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y2_train)\n",
    "model3 = LinearRegression()\n",
    "model3.fit(X_train, y3_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y1_pred = model1.predict(X_test)\n",
    "y2_pred = model2.predict(X_test)\n",
    "y3_pred = model3.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mae1 = mean_absolute_error(y1_test, y1_pred)\n",
    "mae2 = mean_absolute_error(y2_test, y2_pred)\n",
    "mae3 = mean_absolute_error(y3_test, y3_pred)\n",
    "mse1 = mean_squared_error(y1_test, y1_pred)\n",
    "mse2 = mean_squared_error(y2_test, y2_pred)\n",
    "mse3 = mean_squared_error(y3_test, y3_pred)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y1_pred = model1.predict(X)\n",
    "y2_pred = model2.predict(X)\n",
    "y3_pred = model3.predict(X)\n",
    "\n",
    "# Select the predictions\n",
    "df[\"Insured Damages ('000 US$)\"] = y1_pred.round()\n",
    "df[\"Total Damages ('000 US$)\"] = y2_pred.round()\n",
    "df['Aid Contribution'] = y3_pred.round()\n",
    "\n",
    "# Evaluate the model\n",
    "mae1 = mean_absolute_error(y1, y1_pred)\n",
    "mae2 = mean_absolute_error(y2, y2_pred)\n",
    "mae3 = mean_absolute_error(y3, y3_pred)\n",
    "mse1 = mean_squared_error(y1, y1_pred)\n",
    "mse2 = mean_squared_error(y2, y2_pred)\n",
    "mse3 = mean_squared_error(y3, y3_pred)\n",
    "\n",
    "print('Mean Absolute Error Insured Damages:', mae1)\n",
    "print('Mean Absolute Error Total Damages:', mae2)\n",
    "print('Mean Absolute Error Aid Contribution:', mae3)\n",
    "print('Root Mean Squared Error Insured Damages:', mse1)\n",
    "print('Root Mean Squared Error Total Damages:', mse2)\n",
    "print('Root Mean Squared Error Aid Contribution:', mse3)\n",
    "\n",
    "# The RMSE values for all three models are relatively low, which suggests that the model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48de48-5a18-4841-8416-fb4664cac3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def millions(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '$%1.1fM' % (x * 1e-6)\n",
    "\n",
    "formatter = FuncFormatter(millions)\n",
    "\n",
    "ys = [y1, y2, y3]\n",
    "labels = [\"Insured Damages ('000 US$)\", \"Total Damages ('000 US$)\", \"Aid Contribution\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(36, 36))\n",
    "\n",
    "plt.suptitle('SCATTER PLOTS OF THE LINEAR REGRESSION MODEL', fontsize=36, ha=\"center\")\n",
    "\n",
    "for i in range(len(ys)):\n",
    "    y = ys[i]\n",
    "    label = labels[i]\n",
    "    axs[i, 0].scatter(X['Start Date TS'].values, y.values, marker='x', c='#33638DFF')\n",
    "    axs[i, 0].tick_params(labelsize = 18)\n",
    "    axs[i, 0].set_xlabel(\"Start Date TS\", fontsize=18)\n",
    "    axs[i, 0].set_ylabel(label, fontsize=18)\n",
    "    axs[i, 0].set_title(f\"Scatter plot of Start Date TS and {label}\", fontsize=24)\n",
    "    axs[i, 0].spines['bottom'].set_visible(True)\n",
    "    axs[i, 0].spines['left'].set_visible(True)\n",
    "    axs[i, 0].spines['top'].set_visible(False)\n",
    "    axs[i, 0].spines['right'].set_visible(False)\n",
    "    axs[i, 0].yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    axs[i, 1].scatter(X['End Date TS'].values, y.values, marker='x', c='#440154FF')\n",
    "    axs[i, 0].tick_params(labelsize = 18)\n",
    "    axs[i, 1].set_xlabel(\"End Date TS\", fontsize=18)\n",
    "    axs[i, 1].set_ylabel(label, fontsize=18)\n",
    "    axs[i, 1].set_title(f\"Scatter plot of End Date TS and {label}\", fontsize=24)\n",
    "    axs[i, 1].spines['bottom'].set_visible(True)\n",
    "    axs[i, 1].spines['left'].set_visible(True)\n",
    "    axs[i, 1].spines['top'].set_visible(False)\n",
    "    axs[i, 1].spines['right'].set_visible(False)\n",
    "    axs[i, 1].yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "# Save the figure\n",
    "#plt.savefig('Analysis/Plots/dataset-missing-values-barplot-original.png', facecolor='white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f966c-7ae8-4bfc-8f9e-8bf0cdbe6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daylight Saving Time (DST) is a term used to describe the period of time in which clocks are moved forward one hour from the standard time in order to maximize\n",
    "# the hours of daylight during the summer months. This period of time is typically observed from March to November in the US and April to October in EU\n",
    "# In order to calculate the DST data for dates prior 2007, the US Naval Observatory's Historical Time Zone data must be referenced. This data includes the start \n",
    "# and end dates of daylight saving time for eyach year, as well as the amount of time that clocks were adjusted.\n",
    "# For dates after 2007, the US Code Title 15 must be referenced. This code contains the standard rules for Daylight Saving Time, which states that the period of \n",
    "# daylight saving time begins on the second Sunday of March and ends on the first Sunday of November\n",
    "# def calculate_dst(date, tz_name):\n",
    "#     # Create a time zone object using the tz_name argument\n",
    "#     tz_obj = pytz.timezone(tz_name)\n",
    "\n",
    "#     # Convert the date to a time zone aware datetime object\n",
    "#     tz_dt = tz_obj.localize(date)\n",
    "\n",
    "#     # Check if DST is in effect at the given datetime\n",
    "#     if tz_dt.dst():\n",
    "#         # If DST is in effect, add the DST offset to the datetime\n",
    "#         dst_date = tz_dt + tz_dt.dst()\n",
    "#     else:\n",
    "#         # If DST is not in effect, the datetime remains unchanged\n",
    "#         dst_date = tz_dt\n",
    "\n",
    "#     return dst_date\n",
    "\n",
    "    \n",
    "# ## TODO FIX THE ABOVE FUNCTION. THERE IS A PROLEM WITH NATIVE AND AWARE WHEN THE FUNCTION IS APPLIED TO THE BELOW COLUMNS\n",
    "# #with alive_bar(len(df.index), force_tty=True) as bar:    \n",
    "# df['DST Start'] = df.apply(lambda row: calculate_dst(row['Start Datetime'], row['Timezone']), axis=1)\n",
    "# df['DST End'] = df.apply(lambda row: calculate_dst(row['End Datetime'], row['Timezone']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
